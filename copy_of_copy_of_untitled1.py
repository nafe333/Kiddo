# -*- coding: utf-8 -*-
"""Copy of Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QDV_QE5xtPIKUhuWkfqHqqG5Bya1xUT
"""

import os
import sys
import numpy as np
import warnings
import librosa #for audio processing
import IPython. display as ipd
from keras.utils import np_utils 
import matplotlib. pyplot as plt
from IPython.display import Audio
from scipy. io import wavfile #for audio processing
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D
from keras.models import Model
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K
K.clear_session()
np.random.seed(1)

warnings. filterwarnings("ignore")

sample_r = 8000
bs = 32

snapshot_folder ='weights'

!pip install librosa==0.8.1

def progressBar(value, endvalue, bar_length=20,job='Job'):

    percent = float(value) / endvalue
    arrow = '-' * int(round(percent * bar_length)-1) + '>'
    spaces = ' ' * (bar_length - len(arrow))

    sys.stdout.write("\r{0} Completion: [{1}] {2}%".format(job,arrow + spaces, int(round(percent * 100))))
    sys.stdout.flush()

from google.colab import drive
drive.mount('/content/drive')

train_audio_path = '/content/drive/MyDrive/ColabNotebook/train/audio'
labels=os.listdir(train_audio_path)

#find count of each label and plot bar graph
no_of_recordings=[]
for label in labels:
    waves = [ f for f in os. listdir(train_audio_path + '/' + label) if f. endswith('.wav' )]
    no_of_recordings. append(len(waves))

# ploting the class distribution
plt. figure(figsize=(30, 5))
index = np. arange(len(labels))
plt. bar(index, no_of_recordings)
plt. xlabel('Commands' , fontsize=12)
plt. ylabel('No of recordings' , fontsize=12)
plt. xticks(index, labels, fontsize=15, rotation=60)
plt. title('No. of recordings for each command' )
plt. show()
labels=[ "yes", "no", "up", "down", "left", "right", "on", "off", "stop", "go"]

train_audio_path = '/content/drive/MyDrive/ColabNotebook/train/audio'
labels=os. listdir(train_audio_path)     
duration_of_recordings=[]
for label in labels:
    waves = [ f for f in os. listdir(train_audio_path + '/' + label) if f. endswith('.wav' )]
    for wav in waves:
        sample_rate, samples = wavfile. read(train_audio_path + '/' + label + '/' + wav)
        duration_of_recordings.append(float(len(samples) /sample_rate))

len_train = len(duration_of_recordings)
plt.title('Durations')
plt.hist(np.array(duration_of_recordings))

train_audio_path = '/content/drive/MyDrive/ColabNotebook/train/audio'
labels=os. listdir(train_audio_path)

def read_data(train_audio_path):
    i =0 
    all_wave = []
    all_label = []
    for label in labels:
        i+=1
        progressBar(i, len(labels), bar_length=20,job='Resampling, Removing shorter commands')
        waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]
        for wav in waves:
            samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)
            samples = librosa.core.resample(samples, sample_rate, sample_r )
            if(len(samples)== 56000) :
               all_wave.append(samples)
               all_label.append(label)
                
    return all_wave, all_label

all_wave, all_label = read_data(train_audio_path)
print(len(all_wave))

sample_r= 56000

train_audio_path ='/content/drive/MyDrive/ColabNotebook/train/audio'
labels=os. listdir(train_audio_path)
le = LabelEncoder()
y=le.fit_transform(all_label)
classes= list(le.classes_)
classes
len(y)

y=np_utils.to_categorical(y, num_classes=len(labels))
len(y)

x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y, test_size = 0.2, random_state=1, shuffle=True)

x_tr = np.array(x_tr).reshape(-1,sample_r,1)
x_val = np.array(x_val).reshape(-1,sample_r,1)

def make_model():
    inputs = Input(shape=(sample_r,1))

    #First Conv1D layer
    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)
    conv = MaxPooling1D(3)(conv)
    conv = Dropout(0.3)(conv)

    #Second Conv1D layer
    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)
    conv = MaxPooling1D(3)(conv)
    conv = Dropout(0.3)(conv)

    #Third Conv1D layer
    conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)
    conv = MaxPooling1D(3)(conv)
    conv = Dropout(0.3)(conv)

    #Fourth Conv1D layer
    conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)
    conv = MaxPooling1D(3)(conv)
    conv = Dropout(0.3)(conv)

    #Flatten layer
    conv = Flatten()(conv)

    #Dense Layer 1
    conv = Dense(256, activation='relu')(conv)
    conv = Dropout(0.3)(conv)

    #Dense Layer 2
    conv = Dense(128, activation='relu')(conv)
    conv = Dropout(0.3)(conv)

    outputs = Dense(len(labels), activation='softmax')(conv)

    model = Model(inputs, outputs)
    model.summary()
    return model

model = make_model()
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

!mkdir model

snapshot_folder='model'
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30, min_delta=0.0001) 
mc = ModelCheckpoint(snapshot_folder+'/best_model.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

history= model.fit(x_tr, y_tr ,epochs=100, callbacks=[es,mc], batch_size=bs, validation_data=(x_val,y_val))

from matplotlib import pyplot as plt
plt.plot(history.history['loss'], label='train') 
plt.plot(history.history['val_loss'], label='test') 
plt.legend() 
plt.show()

from tensorflow import keras
def predict(audio):
    model=keras.models.load_model('/content/model/best_model.hdf5')
    prob=model.predict(audio.reshape(1,sample_r,1))
    index=np.argmax(prob[0])
    return classes[index]

import random
index=random.randint(0,len(x_tr)-1)
samples=x_tr[index].ravel()
print("Audio:",classes[np.argmax(y_tr[index])])
ipd.Audio(samples, rate=sample_r)
print("Text:",predict(samples))

from tensorflow import keras
import tensorflow as tf
model = tf.keras.models.load_model('/content/model/best_model.hdf5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
   f.write(tflite_model)